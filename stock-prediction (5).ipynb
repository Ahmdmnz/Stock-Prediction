{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11045732,"sourceType":"datasetVersion","datasetId":6880646},{"sourceId":11141317,"sourceType":"datasetVersion","datasetId":6949808}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.361880Z","iopub.execute_input":"2025-03-23T21:44:45.362171Z","iopub.status.idle":"2025-03-23T21:44:45.366026Z","shell.execute_reply.started":"2025-03-23T21:44:45.362150Z","shell.execute_reply":"2025-03-23T21:44:45.364944Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stockdata/data.csv\").head(50000)\ndf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.397266Z","iopub.execute_input":"2025-03-23T21:44:45.397539Z","iopub.status.idle":"2025-03-23T21:44:45.768210Z","shell.execute_reply.started":"2025-03-23T21:44:45.397517Z","shell.execute_reply":"2025-03-23T21:44:45.767254Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"      symbol        date      open      high       low     close    volume\n0        AAL  2014-01-02   25.0700   25.8200   25.0600   25.3600   8998943\n1       AAPL  2014-01-02   79.3828   79.5756   78.8601   79.0185  58791957\n2        AAP  2014-01-02  110.3600  111.8800  109.2900  109.7400    542711\n3       ABBV  2014-01-02   52.1200   52.3300   51.5200   51.9800   4569061\n4        ABC  2014-01-02   70.1100   70.2300   69.4800   69.8900   1148391\n...      ...         ...       ...       ...       ...       ...       ...\n49995   FBHS  2014-06-02   39.9700   40.3300   39.6500   40.0000   1096396\n49996     FB  2014-06-02   63.2300   63.5900   62.0500   63.0800  35995537\n49997    FCX  2014-06-02   34.3200   34.3400   33.9800   34.1200   6484761\n49998    FDX  2014-06-02  144.3100  144.9897  143.7200  144.2500   1285542\n49999     FE  2014-06-02   33.8800   33.9000   33.4250   33.5500   2593126\n\n[50000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symbol</th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAL</td>\n      <td>2014-01-02</td>\n      <td>25.0700</td>\n      <td>25.8200</td>\n      <td>25.0600</td>\n      <td>25.3600</td>\n      <td>8998943</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAPL</td>\n      <td>2014-01-02</td>\n      <td>79.3828</td>\n      <td>79.5756</td>\n      <td>78.8601</td>\n      <td>79.0185</td>\n      <td>58791957</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAP</td>\n      <td>2014-01-02</td>\n      <td>110.3600</td>\n      <td>111.8800</td>\n      <td>109.2900</td>\n      <td>109.7400</td>\n      <td>542711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ABBV</td>\n      <td>2014-01-02</td>\n      <td>52.1200</td>\n      <td>52.3300</td>\n      <td>51.5200</td>\n      <td>51.9800</td>\n      <td>4569061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ABC</td>\n      <td>2014-01-02</td>\n      <td>70.1100</td>\n      <td>70.2300</td>\n      <td>69.4800</td>\n      <td>69.8900</td>\n      <td>1148391</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>FBHS</td>\n      <td>2014-06-02</td>\n      <td>39.9700</td>\n      <td>40.3300</td>\n      <td>39.6500</td>\n      <td>40.0000</td>\n      <td>1096396</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>FB</td>\n      <td>2014-06-02</td>\n      <td>63.2300</td>\n      <td>63.5900</td>\n      <td>62.0500</td>\n      <td>63.0800</td>\n      <td>35995537</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>FCX</td>\n      <td>2014-06-02</td>\n      <td>34.3200</td>\n      <td>34.3400</td>\n      <td>33.9800</td>\n      <td>34.1200</td>\n      <td>6484761</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>FDX</td>\n      <td>2014-06-02</td>\n      <td>144.3100</td>\n      <td>144.9897</td>\n      <td>143.7200</td>\n      <td>144.2500</td>\n      <td>1285542</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>FE</td>\n      <td>2014-06-02</td>\n      <td>33.8800</td>\n      <td>33.9000</td>\n      <td>33.4250</td>\n      <td>33.5500</td>\n      <td>2593126</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.769575Z","iopub.execute_input":"2025-03-23T21:44:45.769927Z","iopub.status.idle":"2025-03-23T21:44:45.775166Z","shell.execute_reply.started":"2025-03-23T21:44:45.769893Z","shell.execute_reply":"2025-03-23T21:44:45.774264Z"}},"outputs":[{"name":"stdout","text":"symbol     object\ndate       object\nopen      float64\nhigh      float64\nlow       float64\nclose     float64\nvolume      int64\ndtype: object\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.777274Z","iopub.execute_input":"2025-03-23T21:44:45.777536Z","iopub.status.idle":"2025-03-23T21:44:45.796628Z","shell.execute_reply.started":"2025-03-23T21:44:45.777516Z","shell.execute_reply":"2025-03-23T21:44:45.795733Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"symbol    0\ndate      0\nopen      0\nhigh      0\nlow       0\nclose     0\nvolume    0\ndtype: int64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.797696Z","iopub.execute_input":"2025-03-23T21:44:45.797999Z","iopub.status.idle":"2025-03-23T21:44:45.814126Z","shell.execute_reply.started":"2025-03-23T21:44:45.797973Z","shell.execute_reply":"2025-03-23T21:44:45.813367Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"symbol    0\ndate      0\nopen      0\nhigh      0\nlow       0\nclose     0\nvolume    0\ndtype: int64"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n    \n\n    first_date = pd.to_datetime(first_date_str)\n    last_date = pd.to_datetime(last_date_str)\n    \n    windowed_data = []\n\n    for company, df_company in dataframe.groupby(\"symbol\"):\n        df_company = df_company.copy()\n        \n        if 'date' not in df_company.columns:\n            df_company = df_company.reset_index()\n        df_company['date'] = pd.to_datetime(df_company['date'])\n        df_company.set_index(\"date\", inplace=True)\n\n        # Filter dates\n        df_company = df_company.loc[first_date:last_date]\n\n        # Skip if there's not enough data\n        if len(df_company) < n + 1:\n            continue  \n\n        df_company[\"log_return\"] = np.log(df_company[\"close\"] + 1e-8).diff()  # Add epsilon        \n        feature_columns = [\n            \"log_return\",    \n            \"volume\"         \n        ]\n        \n        df_company = df_company[feature_columns].dropna()\n\n        for i in range(len(df_company) - n):\n            past_values = df_company.iloc[i:i+n].values.flatten()\n            future_close = df_company.iloc[i + n].name  # Date reference\n            windowed_data.append([company] + list(past_values) + [future_close])\n\n    column_names = [\"company\"] + [f\"{col}_t-{i}\" \n                   for i in range(n, 0, -1) \n                   for col in feature_columns] + [\"target_date\"]\n\n    return pd.DataFrame(windowed_data, columns=column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.814939Z","iopub.execute_input":"2025-03-23T21:44:45.815202Z","iopub.status.idle":"2025-03-23T21:44:45.824233Z","shell.execute_reply.started":"2025-03-23T21:44:45.815184Z","shell.execute_reply":"2025-03-23T21:44:45.823487Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"windowed_df = df_to_windowed_df(df, \"2014-01-02\", \"2017-12-29\", n=3)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:45.824929Z","iopub.execute_input":"2025-03-23T21:44:45.825178Z","iopub.status.idle":"2025-03-23T21:44:53.492041Z","shell.execute_reply.started":"2025-03-23T21:44:45.825150Z","shell.execute_reply":"2025-03-23T21:44:53.491125Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(windowed_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.492976Z","iopub.execute_input":"2025-03-23T21:44:53.493299Z","iopub.status.idle":"2025-03-23T21:44:53.502495Z","shell.execute_reply.started":"2025-03-23T21:44:53.493267Z","shell.execute_reply":"2025-03-23T21:44:53.501609Z"}},"outputs":[{"name":"stdout","text":"      company  log_return_t-3  volume_t-3  log_return_t-2  volume_t-2  \\\n0           A        0.012552   1866651.0       -0.004931   1777472.0   \n1           A       -0.004931   1777472.0        0.014200   1463208.0   \n2           A        0.014200   1463208.0        0.016230   2659468.0   \n3           A        0.016230   2659468.0        0.000342   1757647.0   \n4           A        0.000342   1757647.0        0.008863   1623330.0   \n...       ...             ...         ...             ...         ...   \n48055     ZTS       -0.005927   2538724.0        0.004613   2421857.0   \n48056     ZTS        0.004613   2421857.0       -0.002963   4522725.0   \n48057     ZTS       -0.002963   4522725.0        0.006572   4085453.0   \n48058     ZTS        0.006572   4085453.0        0.005553   2395740.0   \n48059     ZTS        0.005553   2395740.0       -0.007192   5791017.0   \n\n       log_return_t-1  volume_t-1 target_date  \n0            0.014200   1463208.0  2014-01-08  \n1            0.016230   2659468.0  2014-01-09  \n2            0.000342   1757647.0  2014-01-10  \n3            0.008863   1623330.0  2014-01-13  \n4            0.000000   2946738.0  2014-01-14  \n...               ...         ...         ...  \n48055       -0.002963   4522725.0  2014-05-23  \n48056        0.006572   4085453.0  2014-05-27  \n48057        0.005553   2395740.0  2014-05-28  \n48058       -0.007192   5791017.0  2014-05-29  \n48059        0.007843   2610773.0  2014-05-30  \n\n[48060 rows x 8 columns]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"windowed_df[\"target_date\"] = pd.to_datetime(windowed_df[\"target_date\"])\ndf[\"date\"] = pd.to_datetime(df[\"date\"])  \nwindowed_df = windowed_df.rename(columns={\"company\": \"symbol\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.503376Z","iopub.execute_input":"2025-03-23T21:44:53.503708Z","iopub.status.idle":"2025-03-23T21:44:53.533831Z","shell.execute_reply.started":"2025-03-23T21:44:53.503677Z","shell.execute_reply":"2025-03-23T21:44:53.533217Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"final_df = windowed_df.merge(\n    df[[\"symbol\", \"date\", \"close\"]],\n    left_on=[\"symbol\", \"target_date\"],  \n    right_on=[\"symbol\", \"date\"],\n    how=\"left\"\n).drop(columns=[\"date\"]).rename(columns={\"close\": \"target_close\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.535966Z","iopub.execute_input":"2025-03-23T21:44:53.536162Z","iopub.status.idle":"2025-03-23T21:44:53.560855Z","shell.execute_reply.started":"2025-03-23T21:44:53.536145Z","shell.execute_reply":"2025-03-23T21:44:53.560242Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"print(final_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.561806Z","iopub.execute_input":"2025-03-23T21:44:53.562083Z","iopub.status.idle":"2025-03-23T21:44:53.570742Z","shell.execute_reply.started":"2025-03-23T21:44:53.562063Z","shell.execute_reply":"2025-03-23T21:44:53.570022Z"}},"outputs":[{"name":"stdout","text":"      symbol  log_return_t-3  volume_t-3  log_return_t-2  volume_t-2  \\\n0          A        0.012552   1866651.0       -0.004931   1777472.0   \n1          A       -0.004931   1777472.0        0.014200   1463208.0   \n2          A        0.014200   1463208.0        0.016230   2659468.0   \n3          A        0.016230   2659468.0        0.000342   1757647.0   \n4          A        0.000342   1757647.0        0.008863   1623330.0   \n...      ...             ...         ...             ...         ...   \n48055    ZTS       -0.005927   2538724.0        0.004613   2421857.0   \n48056    ZTS        0.004613   2421857.0       -0.002963   4522725.0   \n48057    ZTS       -0.002963   4522725.0        0.006572   4085453.0   \n48058    ZTS        0.006572   4085453.0        0.005553   2395740.0   \n48059    ZTS        0.005553   2395740.0       -0.007192   5791017.0   \n\n       log_return_t-1  volume_t-1 target_date  target_close  \n0            0.014200   1463208.0  2014-01-08         58.39  \n1            0.016230   2659468.0  2014-01-09         58.41  \n2            0.000342   1757647.0  2014-01-10         58.93  \n3            0.008863   1623330.0  2014-01-13         58.93  \n4            0.000000   2946738.0  2014-01-14         59.88  \n...               ...         ...         ...           ...  \n48055       -0.002963   4522725.0  2014-05-23         30.53  \n48056        0.006572   4085453.0  2014-05-27         30.70  \n48057        0.005553   2395740.0  2014-05-28         30.48  \n48058       -0.007192   5791017.0  2014-05-29         30.72  \n48059        0.007843   2610773.0  2014-05-30         30.70  \n\n[48060 rows x 9 columns]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"X = final_df.drop(columns=['symbol', 'target_date', 'target_close'])\ny = final_df['target_close']\n\ntrain_size = int(0.8 * len(X))\nX_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\ny_train, y_test = y.iloc[:train_size], y.iloc[train_size:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.571556Z","iopub.execute_input":"2025-03-23T21:44:53.571771Z","iopub.status.idle":"2025-03-23T21:44:53.582552Z","shell.execute_reply.started":"2025-03-23T21:44:53.571753Z","shell.execute_reply":"2025-03-23T21:44:53.581871Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import torch\nfrom sklearn.preprocessing import StandardScaler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_3d = X_train_scaled.reshape(-1, 3, 2)  # 3 time steps, 2 features\nX_test_3d = X_test_scaled.reshape(-1, 3, 2)\n\nX_train_tensor = torch.tensor(X_train_3d, dtype=torch.float32).to(device)\nX_test_tensor = torch.tensor(X_test_3d, dtype=torch.float32).to(device)\n\nscaler_y = StandardScaler()\ny_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\ny_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n\ny_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)  \ny_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32).to(device)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:44:53.583425Z","iopub.execute_input":"2025-03-23T21:44:53.583641Z","iopub.status.idle":"2025-03-23T21:44:53.605247Z","shell.execute_reply.started":"2025-03-23T21:44:53.583622Z","shell.execute_reply":"2025-03-23T21:44:53.604395Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNNLSTM(nn.Module):\n    def __init__(self):\n        super(CNNLSTM, self).__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(2, 8, kernel_size=2, padding=1),\n            nn.BatchNorm1d(8),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n        self.lstm = nn.LSTM(8, 16, batch_first=True)\n        self.fc = nn.Sequential(\n            nn.Linear(16, 8),\n            nn.LayerNorm(8),\n            nn.ReLU(),\n            nn.Linear(8, 1)\n        )\n        \n        for layer in self.modules():\n            if isinstance(layer, nn.Linear):\n                nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n                nn.init.constant_(layer.bias, 0.01)\n\n    def forward(self, x):\n        x = x.permute(0, 2, 1)  # [batch, features, time_steps]\n        x = self.cnn(x)\n        x = x.permute(0, 2, 1)  # [batch, time_steps, features]\n        x, _ = self.lstm(x)\n        return self.fc(x[:, -1, :]).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNNLSTM().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\ncriterion = nn.L1Loss()\n\nbatch_size = 64\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)  \ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n\nfor epoch in range(30):\n    \n    model.train()\n    total_loss = 0\n    \n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        \n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    \n    model.eval()\n    with torch.no_grad():\n        test_preds = model(X_test_tensor)\n        test_loss = criterion(test_preds, y_test_tensor)\n    \n    print(f\"Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Test Loss: {test_loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:47:29.291225Z","iopub.execute_input":"2025-03-23T21:47:29.291666Z","iopub.status.idle":"2025-03-23T21:48:35.462225Z","shell.execute_reply.started":"2025-03-23T21:47:29.291630Z","shell.execute_reply":"2025-03-23T21:48:35.461443Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([48, 1])) that is different to the input size (torch.Size([48])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.l1_loss(input, target, reduction=self.reduction)\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([9612, 1])) that is different to the input size (torch.Size([9612])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.l1_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 0.5915 | Test Loss: 0.3465\nEpoch 2 | Train Loss: 0.4455 | Test Loss: 0.3325\nEpoch 3 | Train Loss: 0.4356 | Test Loss: 0.3292\nEpoch 4 | Train Loss: 0.4322 | Test Loss: 0.3276\nEpoch 5 | Train Loss: 0.4305 | Test Loss: 0.3265\nEpoch 6 | Train Loss: 0.4295 | Test Loss: 0.3259\nEpoch 7 | Train Loss: 0.4284 | Test Loss: 0.3253\nEpoch 8 | Train Loss: 0.4277 | Test Loss: 0.3249\nEpoch 9 | Train Loss: 0.4275 | Test Loss: 0.3248\nEpoch 10 | Train Loss: 0.4268 | Test Loss: 0.3240\nEpoch 11 | Train Loss: 0.4265 | Test Loss: 0.3240\nEpoch 12 | Train Loss: 0.4259 | Test Loss: 0.3237\nEpoch 13 | Train Loss: 0.4259 | Test Loss: 0.3234\nEpoch 14 | Train Loss: 0.4257 | Test Loss: 0.3236\nEpoch 15 | Train Loss: 0.4258 | Test Loss: 0.3233\nEpoch 16 | Train Loss: 0.4251 | Test Loss: 0.3231\nEpoch 17 | Train Loss: 0.4252 | Test Loss: 0.3232\nEpoch 18 | Train Loss: 0.4250 | Test Loss: 0.3230\nEpoch 19 | Train Loss: 0.4248 | Test Loss: 0.3230\nEpoch 20 | Train Loss: 0.4246 | Test Loss: 0.3230\nEpoch 21 | Train Loss: 0.4246 | Test Loss: 0.3227\nEpoch 22 | Train Loss: 0.4244 | Test Loss: 0.3229\nEpoch 23 | Train Loss: 0.4245 | Test Loss: 0.3229\nEpoch 24 | Train Loss: 0.4243 | Test Loss: 0.3226\nEpoch 25 | Train Loss: 0.4240 | Test Loss: 0.3226\nEpoch 26 | Train Loss: 0.4237 | Test Loss: 0.3226\nEpoch 27 | Train Loss: 0.4241 | Test Loss: 0.3225\nEpoch 28 | Train Loss: 0.4239 | Test Loss: 0.3226\nEpoch 29 | Train Loss: 0.4236 | Test Loss: 0.3225\nEpoch 30 | Train Loss: 0.4235 | Test Loss: 0.3223\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}